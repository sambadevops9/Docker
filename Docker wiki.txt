Docker Arcitecture:
------------------

ubuntu@ip-172-31-62-103:~$ sudo apt-get update
ubuntu@ip-172-31-62-103:~$ sudo apt-get install docker.io

sudo groupadd docker
sudo usermod -aG docker $USER
newgrp docker

what is docker?
-- docker is a platfom or ecosyatem around creating and running containers.

what is docker image?
--A Docker image is a read-only template that contains a set of instructions for creating a container that can run on the Docker platform

---docker ecosystem
   >>Docker client
   >>Docker server
   >>docker image
   >>docker compose
   >>docker hub

why use Docker?
-- Docker makes it really easy to install and run software without worrying about setup or dependencies.

What is container?
--Basically there are a few new Linux kernel features (“namespaces” and “cgroups”) that let you isolate processes from each other. When you use those features, you call it “containers”.

difference between docker swarm and docker-compose?
>>The difference lies mostly in the backend, where docker-compose deploys container on a single Docker host, Docker Swarm deploys it across multiple nodes. Loosely speaking, it can still do most things that docker-compose can but it scales it across multiple Docker hosts.

==> Docker is platfom it is running and shipping the applications and container it is portable.
==> Docker is not having any os. It is using EC2-machine os.
==> Docker is state less. Any time it is deleted.
==> Docker container having only libraries remaining files get from host os.
==> Container is nothing but namespace and control groups to create one process. This process not having connection on another container this is called container.
    we add memory and cpu using control groups.
==> Basically there are having a few kurnal features.That let you isolate process from each other.

==> Docker is container management.container having it only oneapplication it will take requried files from the host os.
	-->It does not have any os.
	-->fast performing.Because of not having os.
	-->It has layerd architecture.

what is vertualization?
--> vertualization means run multiple OS on single physical syastem.
--> vertualization every vm is indipendent.
--> Every vm hav different creduntials
--> VM's are not portable.

"Docker Client" Docker client that we are going to use commands.
"Docker server" That is responsible for creating images,running containers,etc.


How to create container?
--> we create container.we need one image that image pull from repository.
    >> Docker Pull ubuntu:16.04  (Ubuntu is the image name 16.04 is the version) with out image we can't create container.
    
    >> Docker run --rm -it ubuntu:16.04  [Now it's move to the container. If you want move to the outside container Ctrl+PQ].
    >> Inside container Ifconfig,ping,nano,curl not working. So as you are intrest install any packages example.
	-- apt update
	-- apt install -y inputils-ping net-tools wegt nano
    >> After checking Ifconfig,ping www.google.com,curl -s http://google.com,nano "hello"

How to Create container you have image?
>>Docker run --rm -dit --name container1 y3478jh7848 (image ID)

How to Run Container/How to connect container?
    To run container using    >> Docker run --rm -it (image name)
    To connect container      >> Docker exec -it (image name) bash


Create container and change to image and push to Repository?
	we have two ways
		1.create container install update and convert to image and push to docker hub.
		2.create docker file.
    --> we create container.we need one image that image pull from repository.
    >> Docker Pull ubuntu:16.04  (Ubuntu is the image name 16.04 is the version) with out image we can't create container.
    
    >> Docker run --rm -it ubuntu:16.04  [Now it's move to the container. If you want move to the outside container Ctrl+PQ].
    >> Inside container Ifconfig,ping,nano,curl not working. So as you are intrest install any packages example.
	-- apt update
	-- apt install -y inputils-ping net-tools wegt nano
    >> After checking Ifconfig,ping www.google.com,curl -s http://google.com,nano "hello"
 Now Running container to move to image.
    >> Docker ps
    >> Docker commit ofob87dea2bc 6421/ubuntu9:v1
		[ofob87dea2bc---------- this is container ID]
		[6421/ubuntu9-----------we give 6421 is the repositry name and ubuntu9 is the name ofthe image]
		[v1 --------------------this is tag]
    >> Docker images [it shows above created image]
    >> Docker login  [this is login to docker hub]
    >> Docker push 6421/ubuntu9:v1 [now push to repositery .this 6421/ubuntu9 repository is created]



Docker Networks:
	this networks are used to our containers are communicate the this networks. Bridge is the default network we did not give any network in container. this is connected bridge net work.
>> Docker network ls [it show's the list of networks]
>> Docker network inspect Bride [It shows the ip of the bride network and details of the bridge network]
>> Docker network create samba [now it's created samba network]
>> Docker network prune [It is delete the networks not having sinage container]

>> Docker run --rm -dit --name container1 --netwok samba y3478jh7848 (inage id)  [Now samba network is connected with container1]


Docker Volumes:
>> Docker volumes ls [it is checking docker avaliable volumes]
>> Docker volumes create name [it is createing the new volumes]

what is the use of Docker Volumes?
--> In case containers are deleted it stores the data in volumes.When you create the new container we used same volume.
	/var/lib/docker/volumes/[volumename]


>> Docker volume create vol1
>> Docker run --rm -dit --name nginx -v vol1:/var/www/html  ubuntu:16.04 bash [nginx is the container name, vol1 is the volume name, vol1:/var/www/html vol1 is mount to the that path, ubuntu:16.04 image name ]
>> Docker run -it nginx bash [To install inside container nginx]
	--> apt install -y nano
	--> apt update && apt install nginx -y
	>> service --status-all [check nginx service running or not]
	>> service nginx start 
	[now check localhost:8001(you are port)]
	after check --cd /var/www/html
>> docker stop nginx [now container deleted]
>> Docker exec -it nginx service status
>> Docker exec -it nginx service start
>> Docker run --rm -dit --name nginx -p 8001:80 -v vol1:/var/www/html mynginx:v1

----> It is possible to use number of containers using singele volume
----> volumes are requrid to DB server [Because of it's stores the data and freqvently change the data so we need volumes in DB server]
----> Volumes are optional in App server and web server

Difference B/W volumes and Bindmods?
Volumes are managed by Docker.
Bindmods are used to create one folder and add to the container.

>> Docker cp file1 nginx1:/temp/file1 [In the docker copy option is also avaliabe]
>> Docker logs Nginx1


Docker file:
------------
	Daily life we are using this commands in docker file.
1.From 2.LABEL 3.WORKDIR 4.RUN 5.ADD 6.COPY 7.EXPOSE 8.CMD 9.ENTRYPOINT

======
FROM ubuntu:16.04  (install the ubuntu:16.04 image)   
LABEL OWNER="samba"(we given owner name)
LABEL EMAIL="sambasivarao.yarram@gmail.com" (we give the email)
ENV REPO="https://github.com/mavaric202/dockertest1.git" (ENV REPO is the we give the github repository)
RUN apt update \    [RUN is to install requrid files in image]
    && apt install -y nginx net-tools curl unzip wegt git \
    && git clone ${REPO} /tmp/website \
    && cp index.html /var/www/html/index.nginx-debian.html \
    && cp scorekeepr.js /var/www/html \
    && cp style.css /var/www/html
ADD dockertest1.tar.gz /var/www/html \ [add is used to download the remote place files and extract the local files ]
COPY test1.html /var/www/html \ [this is just copy the files]
CMD ["nginx","-g","daemon off;"] (this cmd is execute the after cretion of image)--cmd is the used to overrite the data

=======================

differenc B/W CMD and ENTRYPOINT?
--> CMD is used to ovverite the data.
--> ENTRYPOINT is used to as usel printing the data.Don't overrite.

Docker EXPOSE: It is used internally connect and internaly open the container host.


How to RUN docker file? [https://codefresh.io/docker-tutorial/build-docker-image-dockerfiles/]
==> nano dockerfile [it is used to write the docker file code in dockerfile]
-------->sambasiva@LHLL0001:~/Docker$ docker build -t 6421/dockerfile:v1 .
-------->create one directoty. Inside directory we add dockerfile
==> docker build -t 6421/dockerfile:v1 . [Now build the docker file V1 is the tag(or)version . is importent]
	--> with out -t we are not getting repository names
==> docker images [6421/docker file is created]
==> docker run -rm -dit -p 8001:80 6421/dockerfile:v1 [now container is created]
==> docker run -rm -dit -p 8001:80 6421/dockerfile:v1 /bin/bash [ In case cmd file is ovverite container is not created. so using /bin/bash]

Flow of creating container?
==> Dockerfile--------->Image----------->Container



Docker compose:
---> it is only deploye single machine only.it is not possible to deploye multipule machines.
---> It is used to overcome the manual deployement.
---> It is used only developement purpse only.not usefull in prod envvironment.
This compose is used to yml file:(https://github.com/dockersamples/example-voting-app)
version 3.7
service:
	vote:
		build:./vote
		command:python app.py
		volumes:
			- ./vote/app
		ports:
			- "8000:80"
		networks:
			- front-tier
			- back-tire
	result:
		same as above one [change the values,,,,,result and vote,worker,redis,db this are containers]
	worker:
	redis:
	db:
volumes:

volumes for database only



Docker swarm:
	How to enable docker swarm:
	---> creating 3 instens
		docker-host 1(master/leader)192.168.0.11
		docker-host-2(worker)192.168.0.12
		docker-host 3(worker)192.168.0.13
	---> first connect to the docker-host 1  [master]
		>>docker swarm init [In case you getting error] use [docker swarm init --advertise-addr 192.168.0.11] this is run only 
			response:
				docker swarm join --token SWMTKN-1-3gqltvwvz40jawg4keahzppm1b7jqp8hqm7xizbz2jkyjoitx5-1qsjn6ms1kh3w0ij0vih1qkcj 192.168.0.11:2377
	--->copy and paste the respones in docker-host-2 and docker-host-3
	---> Check >>docker node ls [In master-host  it's 3 machines are active]
>>Docker network ls [now creating 2 new networks docker_gwbridege and ovrlay] when the initilaze swarm it is creating.
	---> when creatnig service it id defolt connect to overlay(ingress)
	
	-->Docker Demaon is a service(multiple hosts) it is used to comunicating the above 3 machines (docker swarm join-token worker)
>> docker node pramote docker-host-2 docker-host-3 [this is used to change worker nodes to secound one of the master ]
>> docker node demote docker-host-2 docker-host-3 [this is again go back to the worker]
	--> masters are compalsery 3 to 5 machines
	
What Is Raft Database? (https://docs.docker.com/engine/swarm/raft/)
-->Having the same consistent state across the cluster means that in case of a failure, any Manager node can pick up the tasks and restore the services to a stable state. For example, if the Leader Manager which is responsible for scheduling tasks in the cluster dies unexpectedly, any other Manager can pick up the task of scheduling and re-balance tasks to match the desired state.

>>docker service create --name nginx --publish 8000:80 --replicas 3 6421/newubuntu:V5
----> --replicas 3 [it is the createing the 3 nginx services]
----> 6421/newubuntu:V5 [is the image name]

>> docker service ps nginx [now it's display the running services]
>> docker service rm nginx [now it's remove the running nginx services]
>> docker service scale nginx=3 [now 3 nginx are running. we give 5 it's running 5 nginx's]
>> docker service update nginx --rplicas 3 [now 3 nginx are running.above and this both are same]

----> Docker_Gwbridege: it is internally connected to the containers [just check in >> docker network ls (docker_gwbridege avaliable in docker networks)]

>>docker service create --name nginx --publish 8000:80 --mode globel 6421/newubuntu:V5
  [we have 3 hosts globel mode it will deploye one container for each host ]

>> docker promote node2 [now it's promote to the leader]
>> docker demote note2 [now it's demoted to tha leader]

Docker Swarm labels:
-------------------

	Two types fo services are avaliable.
1.Service created with replicas --replicas 5
2.Global mode --mode global
	--> It will deploye one container for each host.

--->replicas only using for up and down to the applications.(increasing or decreasing container number)
    >>docker service update nginx01 --replicas 3 [now adding 3 containers.we give 5. it's running 5 containers]
    >>docker service scale nginx01=5 [it's running 5 containers. I think both are same]

Label Usage:
------------

	we have 5 hosts         Role       labels
		ip-10-1-1-118 [manage]-->  manager
		ip-10-1-1-119 [worker]-->  Dev
		ip-10-1-1-120 [worker]-->  Dev
		ip-10-1-1-121 [worker]-->  prod
		ip-10-1-1-122 [worker]-->  prod
	now we want add label 2 is Dev another 2 is prod.
		>>docker node update --label-add dev=true ip-10-1-1-119
		---> Now we adding dev label to ip-10-1-1-119 [worker] machine[now it's display swarm visulization dev=true]
		>>docker node update --label-add dev=true ip-10-1-1-120
		---> Now we adding dev label to ip-10-1-1-120 [worker] machine[now it's display swarm visulization dev=true]

		
		>>docker node update --label-add prod=true ip-10-1-1-121
		---> Now we adding prod label to ip-10-1-1-121 [worker] machine[now it's display swarm visulization prod=true]
		>>docker node update --label-add dev=true ip-10-1-1-122
		---> Now we adding prod label to ip-10-1-1-122 [worker] machine[now it's display swarm visulization prod=true]


Now we want deploye Dev only that time we using labels.

>>docker service create --name devnginx --publish 8008:80 --constraint=node.labels.dev==true --replicas 4  6421/nginx:v1
	[this case 4 containers deploye only on dev hosts. becase of we using labels]

Now we want deploye containers in worker only[dev,prod in role]
>>docker service create --name devnginx --publish 8009:80 --constraint=node.role==worker --replicas 4  6421/nginx:v1
	[this case 4 containers deploye only on worker hosts. becase of we using role]


Swarm Rolling Update:
---------------------

	Rolling update means containers are running on swarm cluster in different hosts (ex:6421/nginx:v1) is runing in continers. We want change
(ex:6421/nginx:v2) version. this time don't down containers but same time update version v2. so that time we using swarm rolling update.


>> docker service create --replicas 5 --publish 8003:80 --name nginx --update-perallelism 1 --update-delay 10s 6421/newubuntu:v1

	[--update-perallelism 1 is the update one by one]
	[--update-delay 10s is delay of 10sec.it means update first one delay of 10s to update secound one]

>>docker service update --image 6421/newubuntu:v2
	[it means remove old one and update new version]
	
	
	
Docker swarm-trafik: this is used for controling trafic.
--------------------

	this docker swarm-trafic it is used to the we have 3 hostes in each host running on 2 containers 1 is nginx01 another one is nginx02. this nginx01 service 3 containers are add to the one target group (TCP-8000) another nginx02 service 3 containers are add to the another target group (TCP-9000).nginx01 adding one load balancer and nginx02 add one load balancer. this both are connecting 
Route53(internet)-----------This entair process we are using 2 load balancers.so we spending more money. this problem overcome using
ingress(this is traffic controler) now  we reduse load balancers and cost

---trafic creation are avaliable in (gooledrive)
How to create network in swarm?
>>docker network create --drive=overlay traefik-net(trafic-net is the name)

first craeting trafic service.

>>docker service create --name trafic --constraint=node.role==manager --publish 80:80 --publish 8080:8080  --mount type=bind,
source=/var/run/docker.sock,target=/var/run/docker.sock  --network traefik-net traefik:v1.6 --docker --docker.swarmnode 
--docker.domain=traefik --docker.watch --web  {this is created only managernode onlay. it is running 8080 port}

Now creating servives in under trafic-swarm

>>docker service craete --name nginx01 --label trafic.port=80  --network traefic-net --label traefic.frontend.rule==host:nginx01.awscoffiesop.xyz  6421/newubuntu:v1

>>docker service craete --name nginx02 --label trafic.port=80  --network traefic-net --label traefic.frontend.rule==host:nginx02.awscoffiesop.xyz  6421/newubuntu:v3

>>docker service craete --name nginx03 --label trafic.port=80  --network traefic-net --label traefic.frontend.rule==host:nginx03.awscoffiesop.xyz  6421/newubuntu:v1


Docker stack:   {in github:dockersamples/example-votingapp}check dockerstack.yml
-------------

stack:stack don't do the build.it having deploye
compose:build the image and up the application

git clone voting app
>>nano docker-stack.yml
we can check docker composeavaliable are not. incase not avaliable /github.com/docker/compose/release

run in terminal: curl -l https://github.com/docker/comopose/releases/download/1.25.4/docker-compose-'uname -s' -

>>docker-compose up [this case pull and build the images] >>docker-compose down

in case file name is docker-compose-window.yml
>>docker-compose -f docker-compose-window.yml up -d

docker-stack(it is only used docker swarm cluster) docker-stack.yml

>>docker stack deploy --compose-file docker-stack.yml vote (this vote name is our choice)
>>docker stack rm vote (now delete entaier vote)

---> In compose time containers are createing one host only. In case one host facing any problem entair application is down.
---> In stack deploye creating multiple containers in multiple hosts. in case any container deleted again creating.


Docker secrets:
--------------[it stores the sensitive data](check google drive)

create one service assign secrets:

>>docker secret ls
>>echo "corona@345" | docker secret create pass1 -
>>echo "mask@543" | docker secret create pass2 -
>>docker secret ls
>>docker secret inspect pass2 [it just give the information not showing password]


>>docker service create --neame hello --secrets db_dba_password --secret db_reset_password -p 8000:80 --replicas 6 6421/newubuntu:v1
>>docker exec -it hello bash
-->ls
-->cat /run/secrets/db_dba_password [now showing password]
	[this password creating container memory only not in volumes]
	
Stack file also creating secrets(check google drive)


Resurvation and Limits:
----------------------
this reservations and limits are used to mention menimum reserve size of memory and maximum size of memory limit.

resourse: [using compose file]
	resurvations:
		memory:128M {this container compulsary we give 128 M}
	limits:
		memory:256M {this container limt max 256M} we reach container 256 now it's automaticaly restart.
		
using command line:
>>docker service create --name stress --limit-memory 400 M --replicas 3 6421/newubuntu:v1
>>docker service create --name stress --reserve-memory 100M --limit-memory 400 M  --replicas 3 sreeharsha/strees:256 copy


Docker Config:
-------------

>>docker config create index1 index-1.html
>>docker config create index2 index-2.html

>>docker service create --name nginx01 --config src=index1,target=/user/share/nginx/html/index.html -p 8000:80 
 sreeharshv/rollingupdate:v3
 
 Updateing--
 >>docker service update nginx01 --config-rn index1 --config-add src=index2,target=/user/share/nginx/html/index.html
 
 
 HealthCheck:
 -----------
 
 Creating dockerfile--
 
 FROM nginx:latest
 LABEL NAME ="samba"
 MAINTAINER samba@dgg.com
 COPY index.html /usr/share/nginx/html/
 COPY screkeeper.js /usr/share/nginx/html/
 COPY style.css /usr/share/nginx/html/
 RUN apt update && apt install -y curl
 HEALTHCHECK CMD CURL --fail http://localhost:80/ || exit1
 
 >>docker build -t 6421/healthcheck:v1
 >>docker push 6421/healthcheck:v1
 
 >>docker run --rm -dit --name samba -p 8000:80 6421/healthcheck:v1
 
 >>docker service create --name health01 -p 9000:80 replicas 3 6421/healthcheck:v1



